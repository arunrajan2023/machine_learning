{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                               MACHINE LEARNING                             \n",
      "================================================================================\n",
      "Data...\n",
      "================================================================================\n",
      "Primary features           : (70, 15)\n",
      "\n",
      " \n",
      "================================================================================\n",
      "Boxplot for GW data:\n",
      "Medians       : [2.4012500000000001]\n",
      "fliers        : [ 1.8312  1.7317  1.6075  1.5867  3.3956  3.3659  3.3072  3.2661  3.2553\n",
      "  3.2203]\n",
      "\n",
      "Figure: boxplot_GW_egap.png\n",
      "\n",
      "Best primary data: best-prim.dat\n",
      "================================================================================\n",
      "PRIMARY feature combinations . . . !\n",
      "prim_data :\n",
      "PRIMARY\n",
      "================================================================================\n",
      "#features (r): 1 #nCr : 15\n",
      "\n",
      "KRR :\n",
      "len(nfeature_list[0]) 1\n",
      "================================================================================\n",
      "#features (r): 2 #nCr : 105\n",
      "\n",
      "KRR :\n",
      "len(nfeature_list[0]) 2\n",
      "================================================================================\n",
      "#features (r): 3 #nCr : 455\n",
      "\n",
      "KRR :\n",
      "len(nfeature_list[0]) 3\n",
      "================================================================================\n",
      "#features (r): 4 #nCr : 1365\n",
      "\n",
      "KRR :\n",
      "len(nfeature_list[0]) 4\n",
      "================================================================================\n",
      "#features (r): 5 #nCr : 3003\n",
      "\n",
      "KRR :\n",
      "len(nfeature_list[0]) 5\n",
      "================================================================================\n",
      "#features (r): 6 #nCr : 5005\n",
      "\n",
      "KRR :\n",
      "len(nfeature_list[0]) 6\n",
      "================================================================================\n",
      "#features (r): 7 #nCr : 6435\n",
      "\n",
      "KRR :\n",
      "len(nfeature_list[0]) 7\n",
      "================================================================================\n",
      "#features (r): 8 #nCr : 6435\n",
      "\n",
      "KRR :\n"
     ]
    }
   ],
   "source": [
    "#Machine learning code\n",
    "#Written by Arun \n",
    "#Programming language: Python\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from numpy import linalg              \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split          \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from matplotlib import pyplot as plt\n",
    "import sys, traceback\n",
    "import warnings\n",
    "import random\n",
    "warnings.simplefilter(\"error\")\n",
    "np.seterr(divide='ignore', invalid='ignore')   #skips divide by zero , NaN errors\n",
    "     \n",
    "start = time.time()\t\t\t  #timer\n",
    "file1 = open(\"data-X.dat\",      \"r\")         \n",
    "gwfile= open(\"data-gw.dat\",   \"r\")        \n",
    "\n",
    "#reading data file\n",
    "data   = []\n",
    "for line in file1:\n",
    "\tdata.append( [float(n) for n in line.split()])\n",
    "\n",
    "#reading GW file\n",
    "egap_gw= []\n",
    "for line2 in gwfile:\n",
    "\tegap_gw.append(line2.split())\n",
    "\n",
    "#convert to numpy arrays\n",
    "data    = np.asarray(data,    dtype=float) \n",
    "egap_gw = np.asarray(egap_gw, dtype=float)\n",
    "\n",
    "print(\"\")\n",
    "print(\"=\"*80)\n",
    "print(\"                               MACHINE LEARNING                             \")\n",
    "print(\"=\"*80)\n",
    "\n",
    " \n",
    "#---------------Normalize the given data------------------\n",
    "print(\"Data...\")\n",
    "data_nrow, data_ncol   = data.shape\n",
    "#print(data.shape)\n",
    "\n",
    "# print(\"Normalization (Centering and Scaling). . .\")\n",
    "# #centering\n",
    "# data = StandardScaler().fit_transform(data)\n",
    "\n",
    "# #scale 0-1\n",
    "# data = MinMaxScaler().fit_transform(data)                       \n",
    "# print(\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "#-------------------- primary features--------------------\n",
    "prim_data  = np.copy(data)\n",
    "print(\"Primary features           :\", prim_data.shape)\n",
    "print(\"\")\n",
    "\n",
    "#------------------- #We dont use feature selection here!\n",
    "prim_nrow, prim_ncol = prim_data.shape\n",
    "\n",
    "# #---------------- Correlation co-efficient ------- \n",
    "# print(\"Highly correlated primary features.......\")\n",
    "# corrmax = 0.99\n",
    "# deletep = []\n",
    "# for _prim_ncol in range(prim_ncol):\n",
    "# \tcolumn1 = (prim_data[:,[_prim_ncol]]).T\n",
    "# \tfor _prim_ncol_new in range(prim_ncol):\n",
    "# \t\tcolumn2 = (prim_data[:,[_prim_ncol_new]]).T\n",
    "# \t\tif _prim_ncol < _prim_ncol_new:\n",
    "# \t\t\tcorr    = np.corrcoef(column1, column2)[0, 1]\n",
    "# \t\t\tif corr > corrmax:\n",
    "# \t\t\t\tprint(_prim_ncol, \" & \", _prim_ncol_new, \": corr=\", corr)\n",
    "# \t\t\t\tdeletep.append(_prim_ncol_new)\n",
    "\n",
    "# deletep = np.unique(deletep)\n",
    "# if len(deletep) > 0:\n",
    "# \tprint(len(deletep),\" indices to be deleted:\", deletep)\n",
    "# \tprim_data = np.delete(prim_data, deletep, 1)\n",
    "# \tprint(\"\")\n",
    "# \tprint(\"Primary features (modified):\", prim_data.shape)\n",
    "# \tprim_nrow, prim_ncol = prim_data.shape\n",
    "# else:\n",
    "# \tprint(\"No feature to be deleted.\")\n",
    "# print(\"\")\n",
    "\n",
    "X = np.copy(prim_data)\n",
    "y = np.copy(egap_gw)\n",
    "print(\" \")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Boxplot for GW data:\")\n",
    "plt.figure(0)\n",
    "bplot    = plt.boxplot(y)\n",
    "print(\"Medians       :\", [item.get_ydata()[0] for item in bplot['medians']])\n",
    "#fliers  = [item.get_ydata() for item in bplot['fliers']]\n",
    "fliers   = []\n",
    "for _fliers in bplot['fliers']:\n",
    "\t_fliers  = _fliers.get_ydata()\n",
    "\tfliers.append(_fliers)\n",
    "\n",
    "fliers  = np.asarray(fliers)\n",
    "print(\"fliers        :\", fliers.ravel())\n",
    "print(\"\")\n",
    "print(\"Figure: boxplot_GW_egap.png\")\n",
    "plt.savefig(\"boxplot_GW_egap.png\")\n",
    "print(\"\")\n",
    "\n",
    "# print(\"Removing outliers from GW data:\")\n",
    "# outlier_index = []\n",
    "# _ycounter     = 0\n",
    "# for _y in y.ravel():\n",
    "# \tfor _fliers in fliers.ravel():\n",
    "# \t\tif float(_y) == float(_fliers):\t     #outlier listed\n",
    "# \t\t\toutlier_index.append(_ycounter)\n",
    "# \t_ycounter += 1\n",
    "\n",
    "# outlier_index = np.unique(outlier_index)\n",
    "# if len(outlier_index) > 0:\n",
    "# \tfor _outlier_index in outlier_index.ravel():\n",
    "# \t\tprint(_outlier_index, \"    :   \", y[_outlier_index])\n",
    "\n",
    "# \tX \t  = np.delete(X, outlier_index, 0)\t\t#deleting outliers from y (and hence from X)\n",
    "# \ty \t  = np.copy(np.delete(y, outlier_index, 0))\n",
    "# \tprim_data = np.delete(prim_data, outlier_index, 0)      #remove corresponding samples from prim_data\n",
    "# #\tcomp_data = np.delete(comp_data, outlier_index, 0)\n",
    "\n",
    "# \tprint(\"\")\n",
    "# \tprint(\"X                 :\", X.shape)\n",
    "# \tprint(\"y                 :\", y.shape)\n",
    "\n",
    "# #\tcomp_nrow, comp_ncol \t= comp_data.shape\n",
    "# \tprim_nrow, prim_ncol \t= prim_data.shape\n",
    "# \tprint(\"Updated X, y & prim_data!\")\n",
    "\t\n",
    "# else:\n",
    "# \tprint(\"Outliers not found!\")\n",
    "# print(\"Done\")\n",
    "# print(\"\")\n",
    "# X                       = np.copy(X)\n",
    "X                       = np.copy(prim_data)\n",
    "prim_nrow, prim_ncol    = prim_data.shape\n",
    "print(\"Best primary data: best-prim.dat\")\n",
    "np.savetxt('best-prim.dat', prim_data, fmt='%15.8f', \n",
    "    delimiter=' ', newline='\\n', header='', footer='', comments='# ')\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PRIMARY feature combinations . . . !\")\n",
    "test_size                 = 0.10\n",
    "_n_estimators             = 100\n",
    "_ntrials                  = 50\n",
    "nplots                    = 2            #2 plots/feature combination/algorithm\n",
    "comb_data_set  \t          = ['prim_data']\n",
    "\n",
    "\n",
    "for _comb_data_set in range(len(comb_data_set)):\n",
    "    print(comb_data_set[_comb_data_set],\":\")\n",
    "    if _comb_data_set == 0:\n",
    "        comb_data = np.copy(prim_data)\n",
    "        print(\"PRIMARY\")\n",
    "    else:\n",
    "        print(\"Not PRIMARY . . . stopping!\")\n",
    "        sys.exit()\n",
    "    \n",
    "    comb_nrow, comb_ncol = comb_data.shape\n",
    "    ctr         = 0\n",
    "    nfeature    = np.arange(comb_ncol)    \n",
    "    \n",
    "    regression = [\"KRR\"]\n",
    "    #regression = [\"SVR\"]\n",
    "    nctr       = 0\n",
    "    for _nfeature in nfeature: # 1 to n\n",
    "        print(\"=\"*80)\n",
    "        nctr += 1\n",
    "        for tag in regression:\n",
    "            nfeature_list = list(itertools.combinations(nfeature, _nfeature+1))    #nCr combinations (ex: [1,2], [.,.], etc for 2 feature combinations)\n",
    "            print(\"#features (r):\", nctr, \"#nCr :\", len(nfeature_list))\n",
    "            r2_comb      = []                                                              \n",
    "            rmse_comb    = []                                                               \n",
    "            mae_comb     = []                                                               \n",
    "            feature_comb = []  \n",
    "            r2_train_comb      = []                                                              \n",
    "            rmse_train_comb    = []                                                               \n",
    "            mae_train_comb     = []                                                               \n",
    "            feature_train_comb = []             \n",
    "            print(\"\")\n",
    "            print(tag, \":\")\n",
    "            \n",
    "            if len(nfeature_list[0]) != 8:\n",
    "                print(\"len(nfeature_list[0])\", len(nfeature_list[0]))\n",
    "                continue\n",
    "            \n",
    "            for _nfeature_list in nfeature_list:                                            #each combination\n",
    "                    X        = np.copy(comb_data[:, _nfeature_list])         \n",
    "                    comb_nrow, comb_ncol = X.shape      \n",
    "                  \n",
    "                    if tag ==  \"LR\":\n",
    "                        estm            = LinearRegression()\n",
    "                    elif tag == \"Lasso\":\n",
    "                        estm            = LassoCV(tol=0.001,max_iter=10000000)\n",
    "                    elif tag == \"KRR\":\n",
    "                        estm            = GridSearchCV(KernelRidge(kernel='rbf'), cv=5,\n",
    "                        param_grid={\"alpha\": [1e0, 0.5, 0.1, 0.05, 1e-2, 0.005, 1e-3], \"gamma\": np.logspace(-4, 4, 20)})\n",
    "                    elif tag == \"SVR\":\n",
    "                        estm            = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=5,\n",
    "                            param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                            \"gamma\": np.logspace(-2, 2, 5)})\n",
    "                    elif tag == \"AdaBoost\":\n",
    "                        estm            = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), \n",
    "                            n_estimators=100, random_state=int(np.random.rand()*100.0)) \n",
    "                    elif tag == \"Bagging\":\n",
    "#                         estm            = BaggingRegressor(DecisionTreeRegressor())\n",
    "                        estm            = BaggingRegressor(DecisionTreeRegressor(max_depth=4), \n",
    "                            n_estimators=_n_estimators, random_state=int(np.random.rand()*100.0))                         \n",
    "                    else:\n",
    "                        print(\"Unknown algorithm\")\n",
    "                        sys.exit()\n",
    "                \n",
    "                    ntrials  = _ntrials\n",
    "                    r2_array = []\n",
    "                    mse_array= []\n",
    "                    mae_array= []\n",
    "                    r2_train_array = []\n",
    "                    mse_train_array= []\n",
    "                    mae_train_array= []                    \n",
    "                    #print(\"Averaging over\", ntrials, \"trials\")\n",
    "                    for _rs in range(ntrials):\n",
    "                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                            random_state=int(np.random.rand()*100.0))             #train & test. \n",
    "#                         if tag == \"Lasso\" or tag == \"SVR\" or tag == \"AdaBoost\" or tag == \"Bagging\":\n",
    "#                             y_pred          = estm.fit(X_train, y_train.ravel()).predict(X_test)\n",
    "#                         else:\n",
    "                        y_pred              = estm.fit(X_train, y_train.ravel()).predict(X_test)  \n",
    "                        y_pred_train        = estm.fit(X_train, y_train.ravel()).predict(X_train)      \n",
    "                        mse                 = mean_squared_error(y_test, y_pred)\n",
    "                        r2                  = r2_score(y_test, y_pred)\n",
    "                        mae                 = mean_absolute_error(y_test, y_pred)\n",
    "                        \n",
    "                        mse_train           = mean_squared_error(y_train, y_pred_train)\n",
    "                        r2_train            = r2_score(y_train, y_pred_train)\n",
    "                        mae_train           = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "                        if r2 > 0:\n",
    "                            r2_array.append(r2)            \n",
    "                            mse_array.append(mse)          \n",
    "                            mae_array.append(mae)   \n",
    "\n",
    "                            r2_train_array.append(r2_train)            \n",
    "                            mse_train_array.append(mse_train)          \n",
    "                            mae_train_array.append(mae_train) \n",
    "                            \n",
    "                            avg_rmse = np.mean(np.sqrt(mse_array))\n",
    "                            avg_r2   = np.mean(r2_array)     \n",
    "                            avg_mae  = np.mean(mae_array)   \n",
    "                            \n",
    "                            avg_rmse_train = np.mean(np.sqrt(mse_train_array))\n",
    "                            avg_r2_train   = np.mean(r2_train_array)     \n",
    "                            avg_mae_train  = np.mean(mae_train_array)                            \n",
    "\n",
    "                    rmse_comb.append(avg_rmse)                     #metrics for given r.\n",
    "                    r2_comb.append(avg_r2)\n",
    "                    mae_comb.append(avg_mae)\n",
    "                    feature_comb.append(_nfeature_list) \n",
    "                    \n",
    "                    rmse_train_comb.append(avg_rmse_train)                     #metrics for given r.\n",
    "                    r2_train_comb.append(avg_r2_train)\n",
    "                    mae_train_comb.append(avg_mae_train)\n",
    "                                     \n",
    "                    if len(r2_comb) == 0:\n",
    "                        print(\"Negative R2\")\n",
    "#                     else:\n",
    "#                         print(\"feature_comb:\", feature_comb)\n",
    "                                                \n",
    "            #based on max. R2 (RMSE min. R2 max and MAE min are always found different)\n",
    "            index2       = list(r2_comb).index(max(r2_comb))\n",
    "            best_rmse    = rmse_comb[index2]\n",
    "            best_mae     = mae_comb[index2]\n",
    "            best_r2      = r2_comb[index2]\n",
    "            \n",
    "            print(\"Averaged values over\", ntrials, \" cycles:\")\n",
    "            print(\"Best features:\", feature_comb[index2])\n",
    "            print(\"Best R2   test/train   :\", round(best_r2,2),   \"/\", round(r2_train_comb[index2],2))\n",
    "            print(\"Best rmse test/train   :\", round(best_rmse,2), \"/\", round(rmse_train_comb[index2],2))\n",
    "            print(\"Best mae  test/train   :\", round(best_mae,2),  \"/\", round(mae_train_comb[index2],2))\n",
    "\n",
    "#if required, the following canbe averaged.\n",
    "#             array_test  = np.array([y_test.ravel(), y_pred.ravel()])\n",
    "#             array_train = np.array([y_train.ravel(), y_pred_train.ravel()])\n",
    "#             print(\"Test  St.err(eV):\", np.std(array_test)/np.sqrt(np.shape(X_test)[0]))\n",
    "#             print(\"Train St.err(eV):\", np.std(array_train)/np.sqrt(np.shape(X_train)[0]))\n",
    "            best_features   = feature_comb[index2]\n",
    "            \n",
    "            \n",
    "#             best_rmse_nCr.append(rmse_array[index2])       #these can be fixed at the end.\n",
    "#             best_mae_nCr.append(mae_array[index2])\n",
    "#             best_r2_nCr.append(r2_array[index2])\n",
    "#             best_feature_nCr.append(feature_comb[index2])             \n",
    "                               \n",
    "            print(\"best_features :\", best_features)\n",
    "            X_model         = np.copy(comb_data[:, best_features])\n",
    "            #X               = np.copy(comb_data[:, _nfeature_list])\n",
    "            \n",
    "            print(\"X_model\", X_model.shape)\n",
    "            print(\"y\",       y.shape)\n",
    "              \n",
    "#             print(\"#nfeature:\", ctr+1, \"alg:\", tag, \". . . scatter plots (max. 2) . . .\")\n",
    "#             ctr          = 0\n",
    "#             plot_counter = 0\n",
    "#             for _rs in range(5 * ntrials):\n",
    "#                         X_train, X_test, y_train, y_test = train_test_split(X_model, y, test_size=test_size, \n",
    "#                             random_state=int(np.random.rand() * 100.0))    #train & test. \n",
    "#                         if tag == \"Lasso\" or tag == \"SVR\" or tag == \"AdaBoost\" or tag == \"Bagging\":\n",
    "#                             y_pred     = estm.fit(X_train, y_train.ravel()).predict(X_test)\n",
    "#                             #y_pred     = estm.fit(X_train, y_train.ravel()).predict(X_test)\n",
    "#                         else:\n",
    "#                             y_pred     = estm.fit(X_train, y_train).predict(X_test)    \n",
    "#                         rmse           = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#                         r2             = r2_score(y_test, y_pred)\n",
    "#                         mae            = mean_absolute_error(y_test, y_pred)\n",
    "                        \n",
    "#                         lower_rmse     = best_rmse  - 0.1   \n",
    "#                         upper_rmse     = best_rmse  + 0.1    \n",
    "                        \n",
    "#                         lower_mae      = best_mae   - 0.1    \n",
    "#                         upper_mae      = best_mae   + 0.1  \n",
    "                        \n",
    "#                         lower_r2       = best_r2    - 0.1    \n",
    "#                         upper_r2       = best_r2    + 0.1                                                                    \n",
    "#                         rmse           = np.sqrt(mse)  \n",
    "                        \n",
    "#                         if ((rmse >= lower_rmse) and (rmse <= upper_rmse)) and ((mae >= lower_mae) and (mae <= upper_mae)):\n",
    "#                             if (r2 >= lower_r2) and (r2 <= upper_r2):\n",
    "#                                 plot_counter += 1\n",
    "#                                 #print(tag, \" (limit): rmse, r2, mae\", np.sqrt(mse), r2, mae)\n",
    "#                                 array_test  = np.array([y_test.ravel(), y_pred.ravel()])\n",
    "#                                 array_train = np.array([y_train.ravel(), y_pred_train.ravel()])\n",
    "\n",
    "#                                 if estm == \"Lasso\" or estm == \"SVR\" or estm == \"AdaBoost\":\n",
    "#                                     y_pred_train    = estm.fit(X_train, y_train.ravel()).predict(X_train)\n",
    "#                                 else:\n",
    "#                                     y_pred_train    = estm.fit(X_train, y_train.ravel()).predict(X_train)  \n",
    "\n",
    "#                                 rmse_train      = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "#                                 r2_train        = r2_score(y_train, y_pred_train)\n",
    "#                                 mae_train       = mean_absolute_error(y_train, y_pred_train)\n",
    "#                                 print(\"Test  RMSE (eV) :\", rmse,       \" R2 :\", r2,       \" MAE (eV):\", mae)\n",
    "#                                 print(\"Train RMSE (eV) :\", rmse_train, \" R2 :\", r2_train, \" MAE (eV):\", mae_train)\n",
    "#                                 print(\"Test  St.err(eV):\", np.std(array_test)/np.sqrt(np.shape(X_test)[0]))\n",
    "#                                 print(\"Train St.err(eV):\", np.std(array_train)/np.sqrt(np.shape(X_train)[0]))\n",
    "                                  \n",
    "#                                 plt.figure(int(np.random.rand())*1000)\n",
    "#                                 plt.scatter(y_train, y_pred_train, s=70.0, c=\"red\",  alpha=0.5)\n",
    "#                                 plt.scatter(y_test, y_pred,        s=70.0, c=\"blue\", alpha=0.5)\n",
    "#                                 plt.plot([0.0, 6.0], [0.0, 6.0], color='white', linestyle='--', linewidth=4)\n",
    "#                                 axes = plt.gca()     #the best way to set lim & labels\n",
    "#                                 axes.set_xlim([1.5,5])\n",
    "#                                 axes.set_ylim([1.5,5])\n",
    "#                                 axes.set_ylabel(\"Predicted gap (eV)\")\n",
    "#                                 axes.set_xlabel(\"True gap (eV)\")\n",
    "#                                 axes.set_title(\"{}_{}_{}_{}_{}_{}\".format(nctr,tag,\n",
    "#                                     round(rmse_train,2), round(np.sqrt(mse),2), round(r2_train,2), round(r2,2)))\n",
    "#                                 plt.show()\n",
    "                                                            \n",
    "#                                 test = np.concatenate((y_test.reshape(len(y_test),1), \n",
    "#                                         y_pred.reshape(len(y_test),1)), axis=1)\n",
    "#                                 train = np.concatenate((y_train.reshape(len(y_train),1), \n",
    "#                                         y_pred_train.reshape(len(y_pred_train),1)), axis=1)\n",
    "#                                 np.savetxt(\"case1-{}_{}_train_{}_{}_{}_r{}.{}\".format(nctr,tag,_n_estimators,ntrials,test_size,ctr+1,plot_counter), train)\n",
    "#                                 np.savetxt(\"case1-{}_{}_test_{}_{}_{}_r{}.{}\".format(nctr,tag,_n_estimators,ntrials,test_size,ctr+1,plot_counter), test)\n",
    "#                                 print(\"Saved files : case1-{}_{}_train_{}_{}_{}_r{}.{} & case1-{}_{}_test_{}_{}_{}_r{}.{}\".\n",
    "#                                       format(nctr,tag,_n_estimators,ntrials,test_size,ctr+1,plot_counter,nctr, tag,_n_estimators,ntrials,test_size,ctr+1,plot_counter))\n",
    "                                             \n",
    "#                                 if plot_counter == (nplots + 1):\n",
    "#                                     print(\"Already plotted\", plot_counter, \"plots. Quitting\")\n",
    "#                                     break\n",
    "\n",
    "        ctr         += 1\n",
    "#close files.\n",
    "file1.close()  \n",
    "gwfile.close() \n",
    "\n",
    "#run time\n",
    "end  = time.time()\n",
    "m, s = divmod(end - start, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print(\"Run time: %d:%02d:%02d\" % (h, m, s)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
